#!/usr/bin/env python3
"""
Generate Churn Labels Script
Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ churn Ğ»ĞµĞ¹Ğ±Ğ»Ğ¾Ğ² Ñ Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ¾Ğ¼ 60 Ğ´Ğ½ĞµĞ¹

Author: Customer Data Analytics Team
"""

import os
import sys
import psycopg2
import logging
from datetime import datetime
from pathlib import Path

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº ĞºĞ¾Ñ€Ğ½ĞµĞ²Ğ¾Ğ¹ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

import psycopg2
from psycopg2.extras import RealDictCursor

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('churn_labels_generation.log')
    ]
)
logger = logging.getLogger(__name__)


def execute_sql_file(conn: psycopg2.extensions.connection, file_path: Path) -> bool:
    """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ SQL Ñ„Ğ°Ğ¹Ğ»Ğ°"""
    try:
        logger.info(f"ğŸ”„ Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ {file_path.name}...")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            sql_content = f.read()
        
        with conn.cursor() as cursor:
            cursor.execute(sql_content)
            conn.commit()
            
        logger.info(f"âœ… {file_path.name} Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ {file_path.name}: {e}")
        conn.rollback()
        return False


def check_table_exists(conn: psycopg2.extensions.connection, table_name: str) -> bool:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹"""
    try:
        with conn.cursor() as cursor:
            cursor.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_name = %s
                )
            """, (table_name,))
            return cursor.fetchone()[0]
    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ {table_name}: {e}")
        return False


def get_table_stats(conn: psycopg2.extensions.connection, table_name: str) -> dict:
    """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹"""
    try:
        with conn.cursor() as cursor:
            cursor.execute(f"""
                SELECT 
                    COUNT(*) as total_records,
                    COUNT(*) FILTER (WHERE is_churn_next_60d = TRUE) as churn_count,
                    COUNT(*) FILTER (WHERE is_churn_next_60d = FALSE) as retention_count,
                    COUNT(DISTINCT user_id) as unique_users,
                    COUNT(DISTINCT snapshot_date) as unique_snapshots,
                    MIN(snapshot_date) as earliest_snapshot,
                    MAX(snapshot_date) as latest_snapshot
                FROM {table_name}
            """)
            
            result = cursor.fetchone()
            return {
                'total_records': result[0],
                'churn_count': result[1],
                'retention_count': result[2],
                'unique_users': result[3],
                'unique_snapshots': result[4],
                'earliest_snapshot': result[5],
                'latest_snapshot': result[6]
            }
    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ {table_name}: {e}")
        return {}


def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    logger.info("ğŸš€ Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜ CHURN Ğ›Ğ•Ğ™Ğ‘Ğ›ĞĞ’")
    logger.info("=" * 60)
    
    # ĞŸÑƒÑ‚ÑŒ Ğº SQL Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼
    sql_dir = Path(__file__).parent.parent / 'sql'
    
    # ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
    sql_files = [
        'create_churn_table.sql',      # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹
        'create_churn_labels_60d.sql', # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ»ĞµĞ¹Ğ±Ğ»Ğ¾Ğ²
        'validate_churn_labels.sql'    # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
    ]
    
    conn = None
    try:
        # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ğ‘Ğ”
        logger.info("ğŸ”Œ ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...")
        conn = psycopg2.connect(
            host="localhost",
            database="customer_data",
            user="mikitavalkunovich",
            port="5432"
        )
        logger.info("âœ… ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ñ‚Ñ€Ğ¸Ğ½Ñ‹ Ñ„Ğ¸Ñ‡
        if not check_table_exists(conn, 'ml_user_features_daily_all'):
            logger.error("âŒ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° ml_user_features_daily_all Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°!")
            logger.error("   Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ¸Ñ‚Ñ€Ğ¸Ğ½Ñ‹ Ñ„Ğ¸Ñ‡")
            return False
        
        logger.info("âœ… Ğ’Ğ¸Ñ‚Ñ€Ğ¸Ğ½Ğ° Ñ„Ğ¸Ñ‡ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°")
        
        # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ SQL Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¿Ğ¾ Ğ¿Ğ¾Ñ€ÑĞ´ĞºÑƒ
        for i, sql_file in enumerate(sql_files, 1):
            file_path = sql_dir / sql_file
            
            if not file_path.exists():
                logger.error(f"âŒ SQL Ñ„Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {file_path}")
                continue
                
            logger.info(f"ğŸ“‹ Ğ¨Ğ°Ğ³ {i}/{len(sql_files)}: {sql_file}")
            success = execute_sql_file(conn, file_path)
            
            if not success:
                logger.error(f"âŒ ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ² {sql_file}. ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°.")
                return False
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
        logger.info("ğŸ“Š ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸...")
        stats = get_table_stats(conn, 'ml_labels_churn_60d')
        
        if stats:
            churn_rate = (stats['churn_count'] / stats['total_records']) * 100 if stats['total_records'] > 0 else 0
            
            logger.info("ğŸ¯ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜:")
            logger.info("=" * 40)
            logger.info(f"ğŸ“‹ Ğ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹: {stats['total_records']:,}")
            logger.info(f"ğŸ‘¥ Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹: {stats['unique_users']:,}")
            logger.info(f"ğŸ“… Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞ½Ğ°Ğ¿ÑˆĞ¾Ñ‚Ğ¾Ğ²: {stats['unique_snapshots']}")
            logger.info(f"ğŸ“… ĞŸĞµÑ€Ğ¸Ğ¾Ğ´: {stats['earliest_snapshot']} - {stats['latest_snapshot']}")
            logger.info(f"ğŸ’” Churn ÑĞ»ÑƒÑ‡Ğ°ĞµĞ²: {stats['churn_count']:,} ({churn_rate:.1f}%)")
            logger.info(f"ğŸ’š Retention ÑĞ»ÑƒÑ‡Ğ°ĞµĞ²: {stats['retention_count']:,} ({100-churn_rate:.1f}%)")
            logger.info("=" * 40)
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ ĞºĞ»Ğ°ÑÑĞ¾Ğ²
            if 20 <= churn_rate <= 40:
                logger.info("âœ… Churn rate Ğ² Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ¾Ğ¼ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğµ (20-40%)")
            else:
                logger.warning(f"âš ï¸  Churn rate ({churn_rate:.1f}%) Ğ²Ğ½Ğµ Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ¾Ğ³Ğ¾ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½Ğ°")
        
        logger.info("ğŸ‰ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ CHURN Ğ›Ğ•Ğ™Ğ‘Ğ›ĞĞ’ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")
        return False
        
    finally:
        if conn:
            conn.close()
            logger.info("ğŸ”Œ Ğ¡Ğ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ñ Ğ‘Ğ” Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¾")


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
