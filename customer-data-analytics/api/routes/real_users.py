"""
Real Users API for ML Predictions
API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∏—Ö —Ñ–∏—á–∞–º–∏
"""

from fastapi import APIRouter, Depends, HTTPException, Query
from typing import List, Dict, Any, Optional
import logging
import sys
import os
from datetime import datetime, date

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ shared
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'shared'))
from database.connection import SessionLocal

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π
from models.ml_models import UserFeatures, PredictionRow

logger = logging.getLogger(__name__)
router = APIRouter()


def get_db():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


@router.get(
    "/real-users-with-features",
    summary="Get real users with ML features",
    description="–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∏—Ö ML —Ñ–∏—á–∞–º–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"
)
async def get_real_users_with_features(
    limit: int = Query(100, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", le=1000),
    min_orders: int = Query(1, description="–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤", ge=0),
    snapshot_date: Optional[str] = Query(None, description="–î–∞—Ç–∞ —Å–Ω–∞–ø—à–æ—Ç–∞ (YYYY-MM-DD), –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–µ–≥–æ–¥–Ω—è"),
    db = Depends(get_db)
) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∏—Ö ML —Ñ–∏—á–∞–º–∏
    
    Returns:
        Dict —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ –∏ –∏—Ö —Ñ–∏—á–∞–º–∏ –¥–ª—è ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    """
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞
        if snapshot_date is None:
            snapshot_date = datetime.now().date().isoformat()
        else:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞—Ç—ã
            try:
                datetime.fromisoformat(snapshot_date).date()
            except ValueError:
                raise HTTPException(status_code=400, detail="–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ YYYY-MM-DD")
        
        logger.info(f"üîç –ü–æ–ª—É—á–µ–Ω–∏–µ {limit} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å features –¥–ª—è snapshot_date={snapshot_date}")
        
        # SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∏—Ö —Ñ–∏—á–∞–º–∏
        query = """
        SELECT 
            f.user_id,
            f.recency_days,
            f.frequency_90d,
            f.monetary_180d,
            f.aov_180d,
            f.orders_lifetime,
            f.revenue_lifetime,
            f.categories_unique,
            u.created_at as user_registered_at,
            -- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
            f.snapshot_date,
            (SELECT COUNT(*) FROM orders o WHERE o.user_id = f.user_id AND o.status IN ('paid', 'shipped', 'completed')) as total_orders_count,
            (SELECT MAX(o.created_at::date) FROM orders o WHERE o.user_id = f.user_id AND o.status IN ('paid', 'shipped', 'completed')) as last_order_date,
            (SELECT SUM(oi.quantity * oi.price) 
             FROM orders o 
             JOIN order_items oi ON o.order_id = oi.order_id 
             WHERE o.user_id = f.user_id AND o.status IN ('paid', 'shipped', 'completed')
            ) as total_lifetime_spent
        FROM ml_user_features_daily_all f
        JOIN users u ON f.user_id = u.user_id
        WHERE f.snapshot_date = %s
          AND f.orders_lifetime >= %s
          AND f.recency_days IS NOT NULL
          AND f.frequency_90d IS NOT NULL
          AND f.monetary_180d IS NOT NULL
        ORDER BY f.orders_lifetime DESC, f.monetary_180d DESC
        LIMIT %s
        """
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å  
        from sqlalchemy import text
        result = db.execute(text(query), (snapshot_date, min_orders, limit))
        rows = result.fetchall()
        
        if not rows:
            logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ñ–∏—á–∞–º–∏ –Ω–∞ –¥–∞—Ç—É {snapshot_date}")
            return {
                "users": [],
                "total_count": 0,
                "snapshot_date": snapshot_date,
                "message": f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è snapshot_date={snapshot_date}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã."
            }
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        users = []
        for row in rows:
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Ñ–∏—á–µ–π (row is a tuple-like object)
            features_dict = {
                "recency_days": float(row[1]) if row[1] is not None else None,
                "frequency_90d": int(row[2]) if row[2] is not None else None,
                "monetary_180d": float(row[3]) if row[3] is not None else None,
                "aov_180d": float(row[4]) if row[4] is not None else None,
                "orders_lifetime": int(row[5]) if row[5] is not None else None,
                "revenue_lifetime": float(row[6]) if row[6] is not None else None,
                "categories_unique": int(row[7]) if row[7] is not None else None,
            }
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Ñ–∏—á–µ–π
            features = UserFeatures(**features_dict)
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            prediction_row = PredictionRow(
                user_id=row[0],  # user_id
                snapshot_date=snapshot_date,
                features=features
            )
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è human-readable –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
            user_info = {
                "prediction_row": prediction_row.dict(),
                "user_registered_at": row[8].isoformat() if row[8] else None,  # user_registered_at
                "last_order_date": row[11].isoformat() if row[11] else None,  # last_order_date
                "total_orders_count": row[10] or 0,  # total_orders_count
                "total_lifetime_spent": float(row[12]) if row[12] else 0.0,  # total_lifetime_spent
                
                # –†–∞—Å—á–µ—Ç–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
                "days_since_registration": (
                    datetime.fromisoformat(snapshot_date).date() - row[8].date()
                ).days if row[8] else None,
                
                "days_since_last_order": row[1],  # recency_days
                
                # –ü—Ä–æ—Ñ–∏–ª—å –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
                "customer_profile": get_customer_profile_description(features_dict, row)
            }
            
            users.append(user_info)
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(users)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏")
        
        return {
            "users": users,
            "total_count": len(users),
            "snapshot_date": snapshot_date,
            "parameters": {
                "limit": limit,
                "min_orders": min_orders,
                "snapshot_date": snapshot_date
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ñ–∏—á–∞–º–∏: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {str(e)}")


def get_customer_profile_description(features: Dict[str, Any], row) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ–ª–æ–≤–µ–∫–æ-–ø–æ–Ω—è—Ç–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è –∫–ª–∏–µ–Ω—Ç–∞
    –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    """
    explanations = []
    
    # –ê–Ω–∞–ª–∏–∑ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ (orders_lifetime)
    orders_lifetime = features.get('orders_lifetime', 0) or 0
    if orders_lifetime >= 20:
        explanations.append(f"–æ—á–µ–Ω—å –ª–æ—è–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç ({orders_lifetime} –∑–∞–∫–∞–∑–æ–≤)")
    elif orders_lifetime >= 10:
        explanations.append(f"–ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç ({orders_lifetime} –∑–∞–∫–∞–∑–æ–≤)")
    elif orders_lifetime >= 5:
        explanations.append(f"–∞–∫—Ç–∏–≤–Ω—ã–π –∫–ª–∏–µ–Ω—Ç ({orders_lifetime} –∑–∞–∫–∞–∑–æ–≤)")
    elif orders_lifetime >= 2:
        explanations.append(f"–ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∫–ª–∏–µ–Ω—Ç ({orders_lifetime} –∑–∞–∫–∞–∑–∞)")
    else:
        explanations.append("–Ω–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç")
    
    # –ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–∞–≤–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (recency_days)
    recency_days = features.get('recency_days', 999) or 999
    if recency_days <= 7:
        explanations.append(f"–ø–æ–∫—É–ø–∞–ª –Ω–µ–¥–∞–≤–Ω–æ ({int(recency_days)} –¥–Ω–µ–π –Ω–∞–∑–∞–¥)")
    elif recency_days <= 30:
        explanations.append(f"–ø–æ–∫—É–ø–∞–ª –≤ —ç—Ç–æ–º –º–µ—Å—è—Ü–µ ({int(recency_days)} –¥–Ω–µ–π –Ω–∞–∑–∞–¥)")
    elif recency_days <= 90:
        explanations.append(f"–ø–æ–∫—É–ø–∞–ª –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –º–µ—Å—è—Ü–∞ ({int(recency_days)} –¥–Ω–µ–π –Ω–∞–∑–∞–¥)")
    else:
        explanations.append(f"–¥–∞–≤–Ω–æ –Ω–µ –ø–æ–∫—É–ø–∞–ª ({int(recency_days)} –¥–Ω–µ–π –Ω–∞–∑–∞–¥)")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è (categories_unique)
    categories_unique = features.get('categories_unique', 0) or 0
    if categories_unique >= 7:
        explanations.append(f"–ø–æ–∫—É–ø–∞–µ—Ç –≤ {categories_unique} –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö")
    elif categories_unique >= 4:
        explanations.append(f"—Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –ø–æ–∫—É–ø–∫–∏ ({categories_unique} –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)")
    elif categories_unique >= 2:
        explanations.append(f"–ø–æ–∫—É–ø–∞–µ—Ç –≤ {categories_unique} –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö")
    
    # –ê–Ω–∞–ª–∏–∑ —Å—É–º–º—ã —Ç—Ä–∞—Ç (monetary_180d)
    monetary_180d = features.get('monetary_180d', 0) or 0
    if monetary_180d >= 2000:
        explanations.append(f"–∫—Ä—É–ø–Ω—ã–µ —Ç—Ä–∞—Ç—ã (${int(monetary_180d)} –∑–∞ –ø–æ–ª–≥–æ–¥–∞)")
    elif monetary_180d >= 1000:
        explanations.append(f"—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç—Ä–∞—Ç—ã (${int(monetary_180d)} –∑–∞ –ø–æ–ª–≥–æ–¥–∞)")
    elif monetary_180d >= 500:
        explanations.append(f"—É–º–µ—Ä–µ–Ω–Ω—ã–µ —Ç—Ä–∞—Ç—ã (${int(monetary_180d)} –∑–∞ –ø–æ–ª–≥–æ–¥–∞)")
    
    # –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç—ã (frequency_90d)
    frequency_90d = features.get('frequency_90d', 0) or 0
    if frequency_90d >= 5:
        explanations.append(f"—á–∞—Å—Ç–æ –∑–∞–∫–∞–∑—ã–≤–∞–µ—Ç ({frequency_90d} —Ä–∞–∑ –∑–∞ 90 –¥–Ω–µ–π)")
    elif frequency_90d >= 3:
        explanations.append(f"—Ä–µ–≥—É–ª—è—Ä–Ω–æ –∑–∞–∫–∞–∑—ã–≤–∞–µ—Ç ({frequency_90d} —Ä–∞–∑–∞ –∑–∞ 90 –¥–Ω–µ–π)")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-2 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
    return ", ".join(explanations[:2])


@router.get(
    "/users-features-summary",
    summary="Get features summary statistics",
    description="–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Ñ–∏—á–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
)
async def get_features_summary(
    snapshot_date: Optional[str] = Query(None, description="–î–∞—Ç–∞ —Å–Ω–∞–ø—à–æ—Ç–∞ (YYYY-MM-DD)"),
    db = Depends(get_db)
) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Ñ–∏—á–∞–º"""
    try:
        if snapshot_date is None:
            snapshot_date = datetime.now().date().isoformat()
        
        query = """
        SELECT 
            COUNT(*) as total_users,
            COUNT(CASE WHEN orders_lifetime >= 10 THEN 1 END) as loyal_users,
            COUNT(CASE WHEN recency_days <= 30 THEN 1 END) as recent_buyers,
            COUNT(CASE WHEN categories_unique >= 5 THEN 1 END) as diverse_buyers,
            AVG(recency_days) as avg_recency,
            AVG(frequency_90d) as avg_frequency_90d,
            AVG(monetary_180d) as avg_monetary_180d,
            AVG(orders_lifetime) as avg_orders_lifetime,
            MIN(snapshot_date) as min_snapshot_date,
            MAX(snapshot_date) as max_snapshot_date
        FROM ml_user_features_daily_all 
        WHERE snapshot_date = %s
        """
        
        result = db.execute(text(query), (snapshot_date,))
        row = result.fetchone()
        
        if not row or row.total_users == 0:
            return {
                "snapshot_date": snapshot_date,
                "total_users": 0,
                "message": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∞—Ç—ã"
            }
        
        return {
            "snapshot_date": snapshot_date,
            "total_users": row.total_users,
            "user_segments": {
                "loyal_users": row.loyal_users,
                "recent_buyers": row.recent_buyers,
                "diverse_buyers": row.diverse_buyers
            },
            "average_features": {
                "recency_days": round(float(row.avg_recency), 1) if row.avg_recency else None,
                "frequency_90d": round(float(row.avg_frequency_90d), 1) if row.avg_frequency_90d else None,
                "monetary_180d": round(float(row.avg_monetary_180d), 1) if row.avg_monetary_180d else None,
                "orders_lifetime": round(float(row.avg_orders_lifetime), 1) if row.avg_orders_lifetime else None
            },
            "data_range": {
                "min_snapshot_date": row.min_snapshot_date.isoformat() if row.min_snapshot_date else None,
                "max_snapshot_date": row.max_snapshot_date.isoformat() if row.max_snapshot_date else None
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}")
