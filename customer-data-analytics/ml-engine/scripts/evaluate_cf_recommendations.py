#!/usr/bin/env python3
"""
Collaborative Filtering Recommendations Evaluation
–ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ CF —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π vs baselines

Author: Customer Data Analytics Team
"""

import os
import sys
import numpy as np
import pandas as pd
import psycopg2
import psycopg2.extras
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Tuple
import random

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ü–µ–Ω–∫–∏
EVALUATION_CONFIG = {
    'holdout_days': 7,          # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π –∫–∞–∫ holdout
    'min_user_history': 2,      # –º–∏–Ω–∏–º—É–º 2 –ø–æ–∫—É–ø–∫–∏ –¥–ª—è —É—á–∞—Å—Ç–∏—è –≤ evaluation
    'k_values': [5, 10, 20],    # –∑–Ω–∞—á–µ–Ω–∏—è K –¥–ª—è HitRate@K –∏ NDCG@K
    'sample_size': 300,         # —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
    'random_seed': 42,
    'cf_min_history': 2         # –º–∏–Ω–∏–º—É–º –ø–æ–∫—É–ø–æ–∫ –¥–ª—è CF —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
}

class CFRecommendationEvaluator:
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ CF —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    
    def __init__(self, db_connection_string: str):
        self.db_conn_str = db_connection_string
        self.conn = None
        random.seed(EVALUATION_CONFIG['random_seed'])
        np.random.seed(EVALUATION_CONFIG['random_seed'])
        
    def connect_db(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î"""
        try:
            self.conn = psycopg2.connect(self.db_conn_str)
            logger.info("‚úÖ Connected to database")
        except Exception as e:
            logger.error(f"‚ùå Database connection failed: {e}")
            raise
    
    def create_holdout_split(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """–°–æ–∑–¥–∞–Ω–∏–µ holdout split: train/test"""
        logger.info("üìä Creating holdout split...")
        
        holdout_cutoff = datetime.now(timezone.utc) - timedelta(days=EVALUATION_CONFIG['holdout_days'])
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        query = """
        SELECT 
            user_id,
            product_id,
            event_ts,
            amount
        FROM ml_interactions_implicit
        WHERE event_ts >= NOW() - INTERVAL '60 days'  -- –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –º–µ—Å—è—Ü–∞
        ORDER BY user_id, event_ts
        """
        
        with self.conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:
            cur.execute(query)
            interactions = pd.DataFrame(cur.fetchall())
        
        if interactions.empty:
            raise ValueError("No interactions found for evaluation")
        
        logger.info(f"üìà Loaded {len(interactions)} interactions")
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train –∏ test
        train_interactions = interactions[interactions['event_ts'] < holdout_cutoff]
        test_interactions = interactions[interactions['event_ts'] >= holdout_cutoff]
        
        logger.info(f"üìä Train: {len(train_interactions)} interactions")
        logger.info(f"üìä Test: {len(test_interactions)} interactions")
        
        return train_interactions, test_interactions
    
    def get_evaluation_users(self, train_interactions: pd.DataFrame, test_interactions: pd.DataFrame) -> List[int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è evaluation"""
        logger.info("üë• Selecting users for evaluation...")
        
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π –≤ train
        train_user_counts = train_interactions['user_id'].value_counts()
        eligible_train_users = train_user_counts[
            train_user_counts >= EVALUATION_CONFIG['min_user_history']
        ].index.tolist()
        
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –ø–æ–∫—É–ø–∫–∞–º–∏ –≤ test
        test_users = test_interactions['user_id'].unique()
        
        # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
        evaluation_users = list(set(eligible_train_users) & set(test_users))
        
        # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
        if len(evaluation_users) > EVALUATION_CONFIG['sample_size']:
            evaluation_users = random.sample(evaluation_users, EVALUATION_CONFIG['sample_size'])
        
        logger.info(f"üë§ Selected {len(evaluation_users)} users for evaluation")
        return evaluation_users
    
    def get_cf_recommendations_for_user(self, user_id: int, k: int, train_interactions: pd.DataFrame) -> List[int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ CF —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–∏–º–∏—Ç–∏—Ä—É–µ–º –ª–æ–≥–∏–∫—É –∏–∑ API)"""
        
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ–∫—É–ø–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Ç–æ–ª—å–∫–æ train)
        user_history = train_interactions[train_interactions['user_id'] == user_id]
        
        if len(user_history) < EVALUATION_CONFIG['cf_min_history']:
            return []
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –ø–æ–∫—É–ø–æ–∫
        recent_purchases = user_history.nlargest(5, 'event_ts')['product_id'].tolist()
        
        # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–π –ø–æ–∫—É–ø–∫–∏
        all_candidates = {}
        recency_decay_factor = 0.9
        
        for idx, product_id in enumerate(recent_purchases):
            # –í–µ—Å –ø–æ recency
            recency_weight = recency_decay_factor ** idx
            
            # –ü–æ–ª—É—á–∞–µ–º CF –ø–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã –∏–∑ –ë–î
            similar_query = """
            SELECT similar_product_id, sim_score
            FROM ml_item_sim_cf
            WHERE product_id = %s
            ORDER BY sim_score DESC
            LIMIT 30
            """
            
            with self.conn.cursor() as cur:
                cur.execute(similar_query, (int(product_id),))
                similar_items = cur.fetchall()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            for similar_product_id, sim_score in similar_items:
                # –ò—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –∫—É–ø–ª–µ–Ω–Ω—ã–µ
                if similar_product_id in recent_purchases:
                    continue
                
                cf_score = float(sim_score) * recency_weight
                
                if similar_product_id not in all_candidates:
                    all_candidates[similar_product_id] = 0
                
                all_candidates[similar_product_id] += cf_score
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-K
        sorted_candidates = sorted(all_candidates.items(), key=lambda x: x[1], reverse=True)
        recommendations = [item[0] for item in sorted_candidates[:k]]
        
        return recommendations
    
    def get_popular_baseline(self, k: int, train_interactions: pd.DataFrame) -> List[int]:
        """–ü–æ–ø—É–ª—è—Ä–Ω—ã–π baseline –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        popular_items = train_interactions['product_id'].value_counts().head(k).index.tolist()
        return popular_items
    
    def get_content_based_recommendations(self, user_id: int, k: int, train_interactions: pd.DataFrame) -> List[int]:
        """Content-based baseline (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        user_history = train_interactions[train_interactions['user_id'] == user_id]
        
        if user_history.empty:
            return []
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–æ–∫—É–ø–∫—É –∏ –Ω–∞—Ö–æ–¥–∏–º content-based –ø–æ—Ö–æ–∂–∏–µ
        last_purchase = int(user_history.nlargest(1, 'event_ts')['product_id'].iloc[0])
        
        similar_query = """
        SELECT similar_product_id
        FROM ml_item_sim_content
        WHERE product_id = %s
        ORDER BY sim_score DESC
        LIMIT %s
        """
        
        with self.conn.cursor() as cur:
            cur.execute(similar_query, (last_purchase, int(k)))
            similar_items = [row[0] for row in cur.fetchall()]
        
        return similar_items
    
    def calculate_hitrate(self, recommendations: List[int], actual_purchases: List[int]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ HitRate@K"""
        if not actual_purchases:
            return 0.0
        
        hits = len(set(recommendations) & set(actual_purchases))
        return 1.0 if hits > 0 else 0.0
    
    def calculate_ndcg(self, recommendations: List[int], actual_purchases: List[int]) -> float:
        """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ NDCG@K"""
        if not actual_purchases:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è NDCG: —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å = 1 –µ—Å–ª–∏ —Ç–æ–≤–∞—Ä –∫—É–ø–ª–µ–Ω, 0 –∏–Ω–∞—á–µ
        relevance_scores = []
        for item in recommendations:
            relevance_scores.append(1.0 if item in actual_purchases else 0.0)
        
        # DCG
        dcg = 0.0
        for i, rel in enumerate(relevance_scores):
            dcg += rel / np.log2(i + 2)  # i+2 –ø–æ—Ç–æ–º—É —á—Ç–æ log2(1) = 0
        
        # IDCG (–¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –ø–æ–∫—É–ø–æ–∫)
        ideal_relevance = [1.0] * min(len(actual_purchases), len(recommendations))
        idcg = 0.0
        for i, rel in enumerate(ideal_relevance):
            idcg += rel / np.log2(i + 2)
        
        if idcg == 0:
            return 0.0
        
        return dcg / idcg
    
    def evaluate_cf_recommendations(self) -> Dict:
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è evaluation"""
        logger.info("üéØ Starting CF recommendations evaluation...")
        start_time = datetime.now()
        
        # 1. –°–æ–∑–¥–∞–µ–º holdout split
        train_interactions, test_interactions = self.create_holdout_split()
        
        # 2. –í—ã–±–∏—Ä–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è evaluation
        evaluation_users = self.get_evaluation_users(train_interactions, test_interactions)
        
        if not evaluation_users:
            raise ValueError("No users available for evaluation")
        
        # 3. –û—Ü–µ–Ω–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ K
        results = {}
        
        for k in EVALUATION_CONFIG['k_values']:
            logger.info(f"üìä Evaluating HitRate@{k} and NDCG@{k}...")
            
            cf_hitrates = []
            cf_ndcgs = []
            content_hitrates = []
            content_ndcgs = []
            popular_hitrates = []
            popular_ndcgs = []
            
            # –ü–æ–ª—É—á–∞–µ–º baseline —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ–¥–∏–Ω —Ä–∞–∑
            popular_recs = self.get_popular_baseline(k, train_interactions)
            
            users_processed = 0
            
            for user_id in evaluation_users:
                # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–∫—É–ø–∫–∏ –≤ test
                user_test_purchases = test_interactions[
                    test_interactions['user_id'] == user_id
                ]['product_id'].tolist()
                
                if not user_test_purchases:
                    continue
                
                users_processed += 1
                
                # CF —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                cf_recs = self.get_cf_recommendations_for_user(user_id, k, train_interactions)
                if cf_recs:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ CF –¥–∞–ª —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                    cf_hitrate = self.calculate_hitrate(cf_recs, user_test_purchases)
                    cf_ndcg = self.calculate_ndcg(cf_recs, user_test_purchases)
                    cf_hitrates.append(cf_hitrate)
                    cf_ndcgs.append(cf_ndcg)
                
                # Content-based baseline
                content_recs = self.get_content_based_recommendations(user_id, k, train_interactions)
                content_hitrate = self.calculate_hitrate(content_recs, user_test_purchases)
                content_ndcg = self.calculate_ndcg(content_recs, user_test_purchases)
                content_hitrates.append(content_hitrate)
                content_ndcgs.append(content_ndcg)
                
                # Popular baseline
                popular_hitrate = self.calculate_hitrate(popular_recs, user_test_purchases)
                popular_ndcg = self.calculate_ndcg(popular_recs, user_test_purchases)
                popular_hitrates.append(popular_hitrate)
                popular_ndcgs.append(popular_ndcg)
                
                if users_processed % 50 == 0:
                    logger.info(f"‚è≥ Processed {users_processed} users...")
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            results[f'k_{k}'] = {
                'hitrate': {
                    'cf': np.mean(cf_hitrates) if cf_hitrates else 0,
                    'content_based': np.mean(content_hitrates) if content_hitrates else 0,
                    'popular': np.mean(popular_hitrates) if popular_hitrates else 0
                },
                'ndcg': {
                    'cf': np.mean(cf_ndcgs) if cf_ndcgs else 0,
                    'content_based': np.mean(content_ndcgs) if content_ndcgs else 0,
                    'popular': np.mean(popular_ndcgs) if popular_ndcgs else 0
                },
                'users_with_cf_recs': len(cf_hitrates),
                'total_users_evaluated': users_processed
            }
            
            logger.info(f"‚úÖ K={k} - CF HitRate: {results[f'k_{k}']['hitrate']['cf']:.3f}, "
                       f"Content: {results[f'k_{k}']['hitrate']['content_based']:.3f}, "
                       f"Popular: {results[f'k_{k}']['hitrate']['popular']:.3f}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        end_time = datetime.now()
        evaluation_duration = end_time - start_time
        
        results['metadata'] = {
            'evaluation_duration': str(evaluation_duration),
            'holdout_days': EVALUATION_CONFIG['holdout_days'],
            'total_users_evaluated': len(evaluation_users),
            'train_interactions': len(train_interactions),
            'test_interactions': len(test_interactions),
            'evaluation_date': end_time.isoformat()
        }
        
        logger.info("üéâ CF evaluation completed successfully!")
        return results
    
    def run_evaluation(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ evaluation"""
        try:
            self.connect_db()
            results = self.evaluate_cf_recommendations()
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            print("\n" + "="*60)
            print("üìä COLLABORATIVE FILTERING EVALUATION RESULTS")
            print("="*60)
            
            for k_key, data in results.items():
                if k_key == 'metadata':
                    continue
                    
                k = k_key.split('_')[1]
                print(f"\nüéØ K={k}:")
                print(f"   CF Users: {data['users_with_cf_recs']}/{data['total_users_evaluated']}")
                print(f"   HitRate@{k}:")
                print(f"     CF:           {data['hitrate']['cf']:.3f}")
                print(f"     Content-Based: {data['hitrate']['content_based']:.3f}")
                print(f"     Popular:       {data['hitrate']['popular']:.3f}")
                print(f"   NDCG@{k}:")
                print(f"     CF:           {data['ndcg']['cf']:.3f}")
                print(f"     Content-Based: {data['ndcg']['content_based']:.3f}")
                print(f"     Popular:       {data['ndcg']['popular']:.3f}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–∞
                cf_vs_popular = data['hitrate']['cf'] > data['hitrate']['popular']
                cf_vs_content = data['ndcg']['cf'] >= (data['ndcg']['content_based'] * 0.9)  # ¬±10%
                
                if cf_vs_popular:
                    print(f"   ‚úÖ CF BEATS popular baseline on HitRate@{k}!")
                if cf_vs_content:
                    print(f"   ‚úÖ CF comparable to content-based on NDCG@{k}!")
            
            print(f"\nüìà SUMMARY:")
            print(f"   Duration: {results['metadata']['evaluation_duration']}")
            print(f"   Users: {results['metadata']['total_users_evaluated']}")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Evaluation failed: {e}")
            raise
        finally:
            if self.conn:
                self.conn.close()


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    db_connection = "postgresql://mikitavalkunovich@localhost:5432/customer_data"
    
    evaluator = CFRecommendationEvaluator(db_connection)
    results = evaluator.run_evaluation()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    import json
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"cf_evaluation_results_{timestamp}.json"
    
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    logger.info(f"üíæ Results saved to {results_file}")


if __name__ == "__main__":
    main()
