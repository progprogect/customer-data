"""
ML Service for Purchase Probability Predictions
–°–µ—Ä–≤–∏—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è inference

Author: Customer Data Analytics Team
"""

import joblib
import json
import pandas as pd
import numpy as np
import logging
import os
import time
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, date
from pathlib import Path

logger = logging.getLogger(__name__)


class MLModelService:
    """Singleton —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å ML –º–æ–¥–µ–ª—å—é"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(MLModelService, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.model = None
            self.scaler = None
            self.metadata = None
            self.model_version = None
            self.feature_names = None
            self.fill_values = None
            self.load_timestamp = None
            self._initialized = True
            logger.info("ü§ñ ML Model Service –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def load_model(self, model_path: Optional[str] = None) -> bool:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        
        Args:
            model_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –º–æ–¥–µ–ª—å—é (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é)
            
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏
        """
        try:
            if model_path is None:
                model_path = self._find_latest_model()
            
            if not model_path:
                raise FileNotFoundError("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–æ–¥–µ–ª—å—é")
            
            logger.info(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑: {model_path}")
            
            # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
            model_file = Path(model_path) / "xgboost_model.pkl"
            scaler_file = Path(model_path) / "scaler.pkl"
            metadata_file = Path(model_path) / "model_metadata.json"
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
            for file_path in [model_file, scaler_file, metadata_file]:
                if not file_path.exists():
                    raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
            logger.info("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ XGBoost –º–æ–¥–µ–ª–∏...")
            self.model = joblib.load(model_file)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∫–µ–π–ª–µ—Ä–∞
            logger.info("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ StandardScaler...")
            self.scaler = joblib.load(scaler_file)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            logger.info("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
            with open(metadata_file, 'r', encoding='utf-8') as f:
                self.metadata = json.load(f)
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            self.model_version = self.metadata.get('model_version', 'unknown')
            self.feature_names = self.metadata.get('feature_names', [])
            self.fill_values = self.metadata.get('fill_values', {})
            self.load_timestamp = datetime.now().isoformat()
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            self._validate_loaded_model()
            
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            logger.info(f"   üìå –í–µ—Ä—Å–∏—è: {self.model_version}")
            logger.info(f"   üìä –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(self.feature_names)}")
            logger.info(f"   üïê –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏: {self.load_timestamp}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self._reset_model()
            return False
    
    def _find_latest_model(self) -> Optional[str]:
        """–ü–æ–∏—Å–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏"""
        try:
            # –ò—â–µ–º –≤ ml-engine/scripts –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            base_path = Path(__file__).parent.parent.parent / "ml-engine" / "scripts"
            
            if not base_path.exists():
                logger.warning(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {base_path}")
                return None
            
            # –ò—â–µ–º –ø–∞–ø–∫–∏ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º production_model_*
            model_dirs = list(base_path.glob("production_model_*"))
            
            if not model_dirs:
                logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –º–æ–¥–µ–ª—è–º–∏")
                return None
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ (–≤–µ—Ä—Å–∏–∏) –∏ –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é
            latest_model = sorted(model_dirs, reverse=True)[0]
            logger.info(f"üîç –ù–∞–π–¥–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è –º–æ–¥–µ–ª—å: {latest_model}")
            
            return str(latest_model)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –º–æ–¥–µ–ª–∏: {e}")
            return None
    
    def _validate_loaded_model(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        if self.scaler is None:
            raise ValueError("–°–∫–µ–π–ª–µ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
        
        if not self.feature_names:
            raise ValueError("–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        if not self.fill_values:
            raise ValueError("–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è NaN")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å –Ω—É–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã
        if not hasattr(self.model, 'predict_proba'):
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç predict_proba")
        
        if not hasattr(self.scaler, 'transform'):
            raise ValueError("–°–∫–µ–π–ª–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç transform")
        
        logger.info("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ")
    
    def _reset_model(self):
        """–°–±—Ä–æ—Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        self.model = None
        self.scaler = None
        self.metadata = None
        self.model_version = None
        self.feature_names = None
        self.fill_values = None
        self.load_timestamp = None
    
    def is_model_loaded(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å"""
        return self.model is not None and self.scaler is not None
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if not self.is_model_loaded():
            return {"status": "not_loaded"}
        
        return {
            "status": "loaded",
            "model_version": self.model_version,
            "load_timestamp": self.load_timestamp,
            "feature_names": self.feature_names,
            "feature_count": len(self.feature_names),
            "model_performance": self.metadata.get('test_results', {}).get('metrics', {}),
            "fill_values": self.fill_values
        }
    
    def prepare_features(self, features_list: List[Dict[str, Any]]) -> pd.DataFrame:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è inference
        
        Args:
            features_list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            
        Returns:
            pd.DataFrame: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        """
        if not self.is_model_loaded():
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(features_list)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –∑–∞–ø–æ–ª–Ω—è–µ–º NaN
        for feature_name in self.feature_names:
            if feature_name not in df.columns:
                df[feature_name] = self.fill_values.get(feature_name, 0.0)
            else:
                # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –∏–∑ –æ–±—É—á–µ–Ω–∏—è
                fill_value = self.fill_values.get(feature_name, 0.0)
                df[feature_name] = df[feature_name].fillna(fill_value)
        
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –ø–æ—Ä—è–¥–∫—É –∫–æ–ª–æ–Ω–æ–∫
        df_ordered = df[self.feature_names].copy()
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–∫–µ–π–ª–µ—Ä
        df_scaled = pd.DataFrame(
            self.scaler.transform(df_ordered),
            columns=self.feature_names,
            index=df_ordered.index
        )
        
        return df_scaled
    
    def predict_probabilities(self, prepared_features: pd.DataFrame) -> np.ndarray:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ inference
        
        Args:
            prepared_features: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            
        Returns:
            np.ndarray: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∞ 1
        """
        if not self.is_model_loaded():
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        probabilities = self.model.predict_proba(prepared_features)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∞ 1 (purchase = True)
        return probabilities[:, 1]
    
    def predict_batch(self, features_list: List[Dict[str, Any]]) -> Tuple[np.ndarray, float]:
        """
        Batch –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∏–∑–º–µ—Ä–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏
        
        Args:
            features_list: –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            
        Returns:
            Tuple[np.ndarray, float]: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∏ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –º—Å
        """
        start_time = time.time()
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            prepared_features = self.prepare_features(features_list)
            
            # Inference
            probabilities = self.predict_probabilities(prepared_features)
            
            # –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            processing_time_ms = (time.time() - start_time) * 1000
            
            return probabilities, processing_time_ms
            
        except Exception as e:
            processing_time_ms = (time.time() - start_time) * 1000
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ batch –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            raise
    
    def validate_features(self, features: Dict[str, Any]) -> List[str]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            features: –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            
        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        errors = []
        
        for feature_name in self.feature_names:
            if feature_name in features:
                value = features[feature_name]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤–æ–µ –∏–ª–∏ None
                if value is not None and not isinstance(value, (int, float)):
                    errors.append(f"Feature '{feature_name}' must be numeric, got {type(value).__name__}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ñ–∏—á–µ–π
                if value is not None and value < 0:
                    if feature_name in ['frequency_90d', 'monetary_180d', 'aov_180d', 
                                      'orders_lifetime', 'revenue_lifetime', 'categories_unique']:
                        errors.append(f"Feature '{feature_name}' cannot be negative: {value}")
        
        return errors


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
ml_service = MLModelService()
