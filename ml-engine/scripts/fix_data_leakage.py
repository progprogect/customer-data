#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Fix Data Leakage in Training Dataset
–°–∫—Ä–∏–ø—Ç –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —É—Ç–µ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–∏—Å—Ç–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

Author: Customer Data Analytics Team
"""

import psycopg2
import logging
import sys
import os
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('fix_data_leakage.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
DB_CONFIG = {
    'host': 'localhost',
    'dbname': 'customer_data',
    'user': 'mikitavalkunovich',
    'password': '',
    'port': 5432
}

def connect_to_db() -> psycopg2.extensions.connection:
    """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        logger.info("‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
        return conn
    except psycopg2.Error as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise

def execute_sql_file(conn: psycopg2.extensions.connection, file_path: str) -> bool:
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL —Ñ–∞–π–ª–∞"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            sql_content = file.read()
        
        with conn.cursor() as cursor:
            cursor.execute(sql_content)
            conn.commit()
            
        logger.info(f"‚úÖ SQL —Ñ–∞–π–ª {file_path} –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è SQL —Ñ–∞–π–ª–∞ {file_path}: {e}")
        conn.rollback()
        return False

def check_leakage_before(conn: psycopg2.extensions.connection):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Ç–µ—á–µ–∫ –î–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Ç–µ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö –î–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è...")
    
    with conn.cursor() as cursor:
        cursor.execute("""
            SELECT 
                MIN(recency_days) as min_recency,
                MAX(recency_days) as max_recency,
                COUNT(CASE WHEN recency_days < 0 THEN 1 END) as negative_count,
                COUNT(*) as total
            FROM ml_training_dataset
        """)
        result = cursor.fetchone()
        
        if result:
            min_recency, max_recency, negative_count, total = result
            logger.warning(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–û –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:")
            logger.warning(f"  ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π recency: {min_recency}")
            logger.warning(f"  ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π recency: {max_recency}")
            logger.warning(f"  ‚Ä¢ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö recency: {negative_count:,} –∏–∑ {total:,} ({negative_count/total*100:.1f}%)")
            
            if negative_count > 0:
                logger.error(f"üö® –û–ë–ù–ê–†–£–ñ–ï–ù–ê –£–¢–ï–ß–ö–ê: {negative_count:,} —Å—Ç—Ä–æ–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º recency!")
                return False
            else:
                logger.info("‚úÖ –£—Ç–µ—á–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
                return True

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üö® –ó–ê–ü–£–°–ö –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –£–¢–ï–ß–ï–ö –î–ê–ù–ù–´–•")
    logger.info("=" * 60)
    
    # –ü—É—Ç—å –∫ SQL —Ñ–∞–π–ª–∞–º
    sql_dir = os.path.join(os.path.dirname(__file__), '..', 'sql')
    
    # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    sql_files = [
        'compute_ml_user_features_no_leakage.sql',     # –ü–µ—Ä–µ—Å—á–µ—Ç —Ñ–∏—á –±–µ–∑ —É—Ç–µ—á–µ–∫
        'populate_buyers_features_no_leakage.sql',     # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π –±–µ–∑ —É—Ç–µ—á–µ–∫
        'validate_no_data_leakage.sql'                 # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —É—Ç–µ—á–µ–∫
    ]
    
    conn = None
    try:
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
        conn = connect_to_db()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Ç–µ—á–µ–∫ –î–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        leakage_detected = not check_leakage_before(conn)
        
        if not leakage_detected:
            logger.info("‚úÖ –£—Ç–µ—á–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
            return True
        
        logger.info("üõ†Ô∏è –ù–∞—á–∏–Ω–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —É—Ç–µ—á–µ–∫...")
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–æ—Ä—è–¥–∫—É
        for i, sql_file in enumerate(sql_files, 1):
            file_path = os.path.join(sql_dir, sql_file)
            
            if not os.path.exists(file_path):
                logger.error(f"‚ùå SQL —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
                continue
                
            logger.info(f"üîÑ –®–∞–≥ {i}/{len(sql_files)}: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ {sql_file}...")
            success = execute_sql_file(conn, file_path)
            
            if not success:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è {sql_file}. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.")
                return False
        
        # –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        logger.info("üîÑ –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π —Ç–∞–±–ª–∏—Ü—ã
        with conn.cursor() as cursor:
            cursor.execute("TRUNCATE TABLE ml_training_dataset;")
            conn.commit()
        
        # –ü–µ—Ä–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–∑ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ñ–∏—á
        rebuild_sql = os.path.join(sql_dir, 'populate_training_dataset.sql')
        if os.path.exists(rebuild_sql):
            success = execute_sql_file(conn, rebuild_sql)
            if not success:
                logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∏ –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞")
                return False
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        logger.info("üîç –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —É—Ç–µ—á–µ–∫...")
        
        with conn.cursor() as cursor:
            cursor.execute("""
                SELECT 
                    MIN(recency_days) as min_recency,
                    MAX(recency_days) as max_recency,
                    COUNT(CASE WHEN recency_days < 0 THEN 1 END) as negative_count,
                    COUNT(*) as total
                FROM ml_training_dataset
            """)
            result = cursor.fetchone()
            
            if result:
                min_recency, max_recency, negative_count, total = result
                logger.info(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û–°–õ–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:")
                logger.info(f"  ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π recency: {min_recency}")
                logger.info(f"  ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π recency: {max_recency}")
                logger.info(f"  ‚Ä¢ –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö recency: {negative_count:,} –∏–∑ {total:,}")
                logger.info(f"  ‚Ä¢ –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total:,}")
                
                if negative_count == 0:
                    logger.info("üéâ –£–¢–ï–ß–ö–ò –£–°–¢–†–ê–ù–ï–ù–´ –£–°–ü–ï–®–ù–û!")
                    logger.info("‚úÖ –î–ê–¢–ê–°–ï–¢ –ì–û–¢–û–í –ö –ë–ï–ó–û–ü–ê–°–ù–û–ú–£ –û–ë–£–ß–ï–ù–ò–Æ!")
                    return True
                else:
                    logger.error(f"üö® –£–¢–ï–ß–ö–ò –í–°–ï –ï–©–ï –ü–†–ò–°–£–¢–°–¢–í–£–Æ–¢: {negative_count:,} —Å—Ç—Ä–æ–∫")
                    return False
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return False
        
    finally:
        if conn:
            conn.close()
            logger.info("üîê –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ")

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
