#!/usr/bin/env python3
"""
Content-Based Recommendations Evaluation
–ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ content-based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π

Author: Customer Data Analytics Team
"""

import os
import sys
import numpy as np
import pandas as pd
import psycopg2
import psycopg2.extras
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
import random

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ü–µ–Ω–∫–∏
EVALUATION_CONFIG = {
    'holdout_days': 7,          # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π –∫–∞–∫ holdout
    'min_user_history': 2,      # –º–∏–Ω–∏–º—É–º 2 –ø–æ–∫—É–ø–∫–∏ –¥–ª—è —É—á–∞—Å—Ç–∏—è –≤ evaluation
    'k_values': [5, 10, 20],    # –∑–Ω–∞—á–µ–Ω–∏—è K –¥–ª—è HitRate@K
    'sample_size': 500,         # —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
    'random_seed': 42
}

class ContentRecommendationEvaluator:
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ content-based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    
    def __init__(self, db_connection_string: str):
        self.db_conn_str = db_connection_string
        self.conn = None
        random.seed(EVALUATION_CONFIG['random_seed'])
        np.random.seed(EVALUATION_CONFIG['random_seed'])
        
    def connect_db(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î"""
        try:
            self.conn = psycopg2.connect(self.db_conn_str)
            logger.info("‚úÖ Connected to database")
        except Exception as e:
            logger.error(f"‚ùå Database connection failed: {e}")
            raise
    
    def create_holdout_split(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """–°–æ–∑–¥–∞–Ω–∏–µ holdout split: train/test"""
        logger.info("üìä Creating holdout split...")
        
        from datetime import timezone
        holdout_cutoff = datetime.now(timezone.utc) - timedelta(days=EVALUATION_CONFIG['holdout_days'])
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        query = """
        SELECT 
            user_id,
            product_id,
            event_ts,
            amount
        FROM ml_interactions_implicit
        WHERE event_ts >= NOW() - INTERVAL '60 days'  -- –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –º–µ—Å—è—Ü–∞
        ORDER BY user_id, event_ts
        """
        
        with self.conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:
            cur.execute(query)
            interactions = pd.DataFrame(cur.fetchall())
        
        if interactions.empty:
            raise ValueError("No interactions found for evaluation")
        
        logger.info(f"üìà Loaded {len(interactions)} interactions")
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train –∏ test
        train_interactions = interactions[interactions['event_ts'] < holdout_cutoff]
        test_interactions = interactions[interactions['event_ts'] >= holdout_cutoff]
        
        logger.info(f"üìä Train: {len(train_interactions)} interactions")
        logger.info(f"üìä Test: {len(test_interactions)} interactions")
        
        return train_interactions, test_interactions
    
    def get_evaluation_users(self, train_interactions: pd.DataFrame, test_interactions: pd.DataFrame) -> List[int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è evaluation"""
        logger.info("üë• Selecting users for evaluation...")
        
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π –≤ train
        train_user_counts = train_interactions['user_id'].value_counts()
        eligible_train_users = train_user_counts[
            train_user_counts >= EVALUATION_CONFIG['min_user_history']
        ].index.tolist()
        
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å –ø–æ–∫—É–ø–∫–∞–º–∏ –≤ test
        test_users = test_interactions['user_id'].unique()
        
        # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
        evaluation_users = list(set(eligible_train_users) & set(test_users))
        
        # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
        if len(evaluation_users) > EVALUATION_CONFIG['sample_size']:
            evaluation_users = random.sample(evaluation_users, EVALUATION_CONFIG['sample_size'])
        
        logger.info(f"üë§ Selected {len(evaluation_users)} users for evaluation")
        return evaluation_users
    
    def get_content_recommendations_for_user(self, user_id: int, k: int, train_interactions: pd.DataFrame) -> List[int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ content-based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ–∫—É–ø–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Ç–æ–ª—å–∫–æ train)
        user_history = train_interactions[train_interactions['user_id'] == user_id]
        
        if user_history.empty:
            return []
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –ø–æ–∫—É–ø–∫–∏
        recent_purchases = user_history.nlargest(3, 'event_ts')['product_id'].tolist()
        
        # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–π –ø–æ–∫—É–ø–∫–∏
        all_candidates = {}
        
        for product_id in recent_purchases:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã –∏–∑ –ë–î
            similar_query = """
            SELECT similar_product_id, sim_score
            FROM ml_item_sim_content
            WHERE product_id = %s
            ORDER BY sim_score DESC
            LIMIT 20
            """
            
            with self.conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:
                cur.execute(similar_query, (product_id,))
                similar_items = cur.fetchall()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            for item in similar_items:
                candidate_id = item['similar_product_id']
                score = item['sim_score']
                
                # –ò—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –∫—É–ø–ª–µ–Ω–Ω—ã–µ
                if candidate_id in user_history['product_id'].values:
                    continue
                
                if candidate_id not in all_candidates:
                    all_candidates[candidate_id] = 0
                
                all_candidates[candidate_id] += score
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-K
        sorted_candidates = sorted(all_candidates.items(), key=lambda x: x[1], reverse=True)
        recommendations = [item[0] for item in sorted_candidates[:k]]
        
        return recommendations
    
    def get_popular_baseline(self, k: int, train_interactions: pd.DataFrame) -> List[int]:
        """–ü–æ–ø—É–ª—è—Ä–Ω—ã–π baseline –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        popular_items = train_interactions['product_id'].value_counts().head(k).index.tolist()
        return popular_items
    
    def get_random_baseline(self, k: int) -> List[int]:
        """–°–ª—É—á–∞–π–Ω—ã–π baseline"""
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
        query = """
        SELECT product_id 
        FROM ml_item_content_features 
        WHERE is_active = true
        """
        
        with self.conn.cursor() as cur:
            cur.execute(query)
            all_products = [row[0] for row in cur.fetchall()]
        
        return random.sample(all_products, min(k, len(all_products)))
    
    def calculate_hitrate(self, recommendations: List[int], actual_purchases: List[int]) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ HitRate@K"""
        if not actual_purchases:
            return 0.0
        
        hits = len(set(recommendations) & set(actual_purchases))
        return 1.0 if hits > 0 else 0.0
    
    def evaluate_recommendations(self) -> Dict:
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è evaluation"""
        logger.info("üéØ Starting content-based recommendations evaluation...")
        start_time = datetime.now()
        
        # 1. –°–æ–∑–¥–∞–µ–º holdout split
        train_interactions, test_interactions = self.create_holdout_split()
        
        # 2. –í—ã–±–∏—Ä–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è evaluation
        evaluation_users = self.get_evaluation_users(train_interactions, test_interactions)
        
        if not evaluation_users:
            raise ValueError("No users available for evaluation")
        
        # 3. –û—Ü–µ–Ω–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ K
        results = {}
        
        for k in EVALUATION_CONFIG['k_values']:
            logger.info(f"üìä Evaluating HitRate@{k}...")
            
            content_hitrates = []
            popular_hitrates = []
            random_hitrates = []
            
            # –ü–æ–ª—É—á–∞–µ–º baseline —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ–¥–∏–Ω —Ä–∞–∑
            popular_recs = self.get_popular_baseline(k, train_interactions)
            
            for i, user_id in enumerate(evaluation_users):
                # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–∫—É–ø–∫–∏ –≤ test
                user_test_purchases = test_interactions[
                    test_interactions['user_id'] == user_id
                ]['product_id'].tolist()
                
                if not user_test_purchases:
                    continue
                
                # Content-based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                content_recs = self.get_content_recommendations_for_user(user_id, k, train_interactions)
                content_hitrate = self.calculate_hitrate(content_recs, user_test_purchases)
                content_hitrates.append(content_hitrate)
                
                # Popular baseline
                popular_hitrate = self.calculate_hitrate(popular_recs, user_test_purchases)
                popular_hitrates.append(popular_hitrate)
                
                # Random baseline  
                random_recs = self.get_random_baseline(k)
                random_hitrate = self.calculate_hitrate(random_recs, user_test_purchases)
                random_hitrates.append(random_hitrate)
                
                if (i + 1) % 50 == 0:
                    logger.info(f"‚è≥ Processed {i + 1}/{len(evaluation_users)} users...")
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            results[f'hitrate@{k}'] = {
                'content_based': np.mean(content_hitrates) if content_hitrates else 0,
                'popular_baseline': np.mean(popular_hitrates) if popular_hitrates else 0,
                'random_baseline': np.mean(random_hitrates) if random_hitrates else 0,
                'users_evaluated': len(content_hitrates)
            }
            
            logger.info(f"‚úÖ HitRate@{k} - Content: {results[f'hitrate@{k}']['content_based']:.3f}, "
                       f"Popular: {results[f'hitrate@{k}']['popular_baseline']:.3f}, "
                       f"Random: {results[f'hitrate@{k}']['random_baseline']:.3f}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        end_time = datetime.now()
        evaluation_duration = end_time - start_time
        
        results['metadata'] = {
            'evaluation_duration': str(evaluation_duration),
            'holdout_days': EVALUATION_CONFIG['holdout_days'],
            'total_users_evaluated': len(evaluation_users),
            'train_interactions': len(train_interactions),
            'test_interactions': len(test_interactions),
            'evaluation_date': end_time.isoformat()
        }
        
        logger.info("üéâ Evaluation completed successfully!")
        return results
    
    def run_evaluation(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ evaluation"""
        try:
            self.connect_db()
            results = self.evaluate_recommendations()
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            print("\n" + "="*60)
            print("üìä CONTENT-BASED RECOMMENDATIONS EVALUATION RESULTS")
            print("="*60)
            
            for metric, data in results.items():
                if metric == 'metadata':
                    continue
                    
                print(f"\nüéØ {metric.upper()}:")
                print(f"   Content-Based:    {data['content_based']:.3f}")
                print(f"   Popular Baseline: {data['popular_baseline']:.3f}")
                print(f"   Random Baseline:  {data['random_baseline']:.3f}")
                print(f"   Users Evaluated:  {data['users_evaluated']}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–∞ –Ω–∞–¥ baseline
                if data['content_based'] > data['popular_baseline']:
                    print(f"   ‚úÖ Content-based BEATS popular baseline!")
                else:
                    print(f"   ‚ö†Ô∏è Content-based below popular baseline")
            
            print(f"\nüìà SUMMARY:")
            print(f"   Total Users: {results['metadata']['total_users_evaluated']}")
            print(f"   Duration: {results['metadata']['evaluation_duration']}")
            print(f"   Holdout: {results['metadata']['holdout_days']} days")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Evaluation failed: {e}")
            raise
        finally:
            if self.conn:
                self.conn.close()


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    db_connection = "postgresql://mikitavalkunovich@localhost:5432/customer_data"
    
    evaluator = ContentRecommendationEvaluator(db_connection)
    results = evaluator.run_evaluation()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    import json
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"content_evaluation_results_{timestamp}.json"
    
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    logger.info(f"üíæ Results saved to {results_file}")


if __name__ == "__main__":
    main()
